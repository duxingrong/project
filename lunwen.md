# 基于机器人实时点云双向建模在增强现实中的应用

## 成果
提出了一种基于AR的实时3D场景渲染方法，总体的建图过程:ros使用LOAM算法处理点云数据->ros#->unity中使用VFX渲染点云信息->HoloLens2可视化

## 方法
1. 数据采集：使用低分辨率移动LiDAR(Velodyne-16)
2. IMU数据与LOAM算法进行定位与地图构建
3. 点云数据增强: 纹理信息增强
4. 点云数据合并和下采样
5. 机器人与AR坐标系对齐
6. 背景渲染和场景合成


## 结果
实时场景扫描可以通过HoloLens2显示，并能够处理动态物体

## 知识点

- ros中的LOAM点云处理算法
- unity中的VFX点云渲染插件


## 如何实现的空间对齐(环境特征对齐)
利用机器人的IMU数据，可以获得设备在扫描过程中每个位置的姿态信息(旋转角度和速度)

LOLAM算法: 是一种专门用来处理激光雷达点云数据的算法，可以将每一个点云数据转换到一个统一的坐标系中

本文结合上面两点，将所有的点云数据转换到机器人起始位置的坐标系中。

AR方面利用自己的相机设备建立自己的虚拟环境地图


由于他们处在相同的物理环境中，环境中的物理特征(如墙壁，柱子，门)对于两者来说是共享的，在某个时刻，通过标定或者多次扫描，他们可以推测出彼此在环境中的相对位置，从而实现坐标系的对齐。



## 启发
实现AR眼镜建立虚拟地图
实现环境特征对齐
